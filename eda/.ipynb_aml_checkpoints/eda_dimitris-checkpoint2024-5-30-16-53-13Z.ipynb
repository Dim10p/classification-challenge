{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting llama-cpp-python\n  Downloading llama_cpp_python-0.2.79.tar.gz (50.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\n\u001b[?25hCollecting diskcache>=5.6.1\n  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from llama-cpp-python) (3.1.4)\nRequirement already satisfied: numpy>=1.20.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from llama-cpp-python) (1.22.0)\nRequirement already satisfied: typing-extensions>=4.5.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from llama-cpp-python) (4.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\nBuilding wheels for collected packages: llama-cpp-python\n  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719761730297
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from   langchain.llms import LlamaCpp\n",
        "\n",
        "# enable verbose to debug the LLM's operation\n",
        "verbose = False\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"/home/chris/MODELS/synthia-7b-v2.0-16k.Q4_K_M.gguf\",\n",
        "    # max tokens the model can account for when processing a response\n",
        "    # make it large enough for the question and answer\n",
        "    n_ctx=4096,\n",
        "    # number of layers to offload to the GPU \n",
        "    # GPU is not strictly required but it does help\n",
        "    n_gpu_layers=32,\n",
        "    # number of tokens in the prompt that are fed into the model at a time\n",
        "    n_batch=1024,\n",
        "    # use half precision for key/value cache; set to True per langchain doc\n",
        "    f16_kv=True,\n",
        "    verbose=verbose,\n",
        ")\n",
        "\n",
        "while True:\n",
        "    question = input(\"Ask me a question: \")\n",
        "    if question == \"stop\":\n",
        "        sys.exit(1)\n",
        "    output = llm(\n",
        "        question,\n",
        "        max_tokens=4096,\n",
        "        temperature=0.2,\n",
        "        # nucleus sampling (mass probability index)\n",
        "        # controls the cumulative probability of the generated tokens\n",
        "        # the higher top_p the more diversity in the output\n",
        "        top_p=0.1\n",
        "    )\n",
        "    print(f\"\\n{output}\") "
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m   \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaCpp\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# enable verbose to debug the LLM's operation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719761732667
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Dummy data for job descriptions\n",
        "job_descriptions = [\n",
        "    'Design and develop software applications using Python and Django framework.',\n",
        "    'Apply machine learning algorithms to analyze and interpret data sets.',\n",
        "    'Lead a team of sales executives to achieve quarterly revenue targets.',\n",
        "    'Develop and execute marketing campaigns across digital platforms.',\n",
        "    'Provide timely and accurate support to customers via phone and email.',\n",
        "    'Define product roadmap and prioritize features based on market research.',\n",
        "    'Conduct financial analysis, forecasting, and reporting for business decisions.',\n",
        "    'Coordinate recruitment processes and support HR functions.',\n",
        "    'Manage daily operations and ensure efficient workflow within the department.',\n",
        "    'Create visual concepts using graphic design software and tools.'\n",
        "]\n",
        "\n",
        "# Create DataFrame with job descriptions\n",
        "df = pd.DataFrame(job_descriptions, columns=['Job Description'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "                                     Job Description\n0  Design and develop software applications using...\n1  Apply machine learning algorithms to analyze a...\n2  Lead a team of sales executives to achieve qua...\n3  Develop and execute marketing campaigns across...\n4  Provide timely and accurate support to custome...\n5  Define product roadmap and prioritize features...\n6  Conduct financial analysis, forecasting, and r...\n7  Coordinate recruitment processes and support H...\n8  Manage daily operations and ensure efficient w...\n9  Create visual concepts using graphic design so...\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719759314041
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}